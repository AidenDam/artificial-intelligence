{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmIxAjZFsORB6H8/n4SvZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PsorTheDoctor/Sekcja-SI/blob/master/neural_networks/NSL/document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9jCAk0-lhXt",
        "colab_type": "text"
      },
      "source": [
        "# Graph regularization: Klasyfikacja dokumentów z użyciem grafów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVluc6YkPaR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNtg1sqCR-Bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "735a6c6f-2fa1-4e20-f011-9b2e40e22c20"
      },
      "source": [
        "!pip install -q neural-structured-learning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▏                            | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 32.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30kB 21.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 40kB 18.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 51kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 81kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 92kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 102kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 13.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwQIWnxSKk4",
        "colab_type": "text"
      },
      "source": [
        "## Dependecje i importy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-uMc5mjSHzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "362fe0d7-8aee-41f2-fe57-7921b7125f19"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import neural_structured_learning as nsl\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Reset notebooka\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print('Version: ', tf.__version__)\n",
        "print('Eager mode: ', tf.executing_eagerly())\n",
        "print('GPU is', 'available' if tf.test.is_gpu_available() else 'NOT AVAILABLE')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.0.1\n",
            "Eager mode:  True\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFV-bolnTOTd",
        "colab_type": "text"
      },
      "source": [
        "## Pobranie zbioru danych Cora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIYODjLgTJZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5039d5fa-048f-4f15-c7cd-241abb9e4bd5"
      },
      "source": [
        "%%bash\n",
        "wget --quiet -P /tmp https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
        "tar -C /tmp -xvzf /tmp/cora.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cora/\n",
            "cora/README\n",
            "cora/cora.content\n",
            "cora/cora.cites\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1zWmJhbTklj",
        "colab_type": "text"
      },
      "source": [
        "## Konwersja danych Cora na format NSL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGHCnC2yTqhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "0e568351-1a36-4986-b934-f470f2cc8a30"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
        "\n",
        "!python preprocess_cora_dataset.py \\\n",
        "--input_cora_content=/tmp/cora/cora.content \\\n",
        "--input_cora_graph=/tmp/cora/cora.cites \\\n",
        "--max_nbrs=5 \\\n",
        "--output_train_data=/tmp/cora/train_merged_examples.tfr \\\n",
        "--output_test_data=/tmp/cora/test_examples.tfr"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-20 23:38:12--  https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11419 (11K) [text/plain]\n",
            "Saving to: ‘preprocess_cora_dataset.py’\n",
            "\n",
            "\r          preproces   0%[                    ]       0  --.-KB/s               \rpreprocess_cora_dat 100%[===================>]  11.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-20 23:38:12 (127 MB/s) - ‘preprocess_cora_dataset.py’ saved [11419/11419]\n",
            "\n",
            "Reading graph file: /tmp/cora/cora.cites...\n",
            "Done reading 5429 edges from: /tmp/cora/cora.cites (0.01 seconds).\n",
            "Making all edges bi-directional...\n",
            "Done (0.01 seconds). Total graph nodes: 2708\n",
            "Joining seed and neighbor tf.train.Examples with graph edges...\n",
            "Done creating and writing 2155 merged tf.train.Examples (1.19 seconds).\n",
            "Out-degree histogram: [(1, 386), (2, 468), (3, 452), (4, 309), (5, 540)]\n",
            "Output training data written to TFRecord file: /tmp/cora/train_merged_examples.tfr.\n",
            "Output test data written to TFRecord file: /tmp/cora/test_examples.tfr.\n",
            "Total running time: 0.04 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yxtV2lQUEEi",
        "colab_type": "text"
      },
      "source": [
        "## Zmienne globalne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_td083LUFxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Doświadczalny zbiór danych\n",
        "TRAIN_DATA_PATH = '/tmp/cora/train_merged_examples.tfr'\n",
        "TEST_DATA_PATH = '/tmp/cora/test_examples.tfr'\n",
        "\n",
        "### Stałe użyte do identyfikacji cech sąsiada na wejściu\n",
        "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
        "NBR_WEIGHT_SUFFIX = '_weight'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1TGroY8U1sA",
        "colab_type": "text"
      },
      "source": [
        "## Hiperparametry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHFVYqcvU1RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HParams(object):\n",
        "  '''Hiperparametry użyte do trenowania.'''\n",
        "  def __init__(self):\n",
        "    # parametry zbioru danych\n",
        "    self.num_classes = 10\n",
        "    self.max_seq_length = 1433\n",
        "    # parametry neural graph learning\n",
        "    self.distance_type = nsl.configs.DistanceType.L2\n",
        "    self.graph_regularization_multiplier = 0.1\n",
        "    self.num_neighbors = 1\n",
        "    # architektura modelu\n",
        "    self.num_fc_units = [50, 50]\n",
        "    # parametry trenowania\n",
        "    self.train_epochs = 100\n",
        "    self.batch_size = 128\n",
        "    self.dropout_rate = 0.5\n",
        "    # parametry oceny\n",
        "    self.eval_steps = None  # Wszystkie instancje w zbiorze testowym są oceniane.\n",
        "\n",
        "HPARAMS = HParams()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXcVO2r9Wce8",
        "colab_type": "text"
      },
      "source": [
        "## Załadowanie danych treningowych i testowych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrdpps9WWbGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_example(example_proto):\n",
        "\n",
        "  feature_spec = {\n",
        "      'words': tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
        "                                     tf.int64,\n",
        "                                     default_value=tf.constant(\n",
        "                                         0,\n",
        "                                         dtype=tf.int64,\n",
        "                                         shape=[HPARAMS.max_seq_length])),\n",
        "      'label': tf.io.FixedLenFeature((), tf.int64, default_value=-1)\n",
        "  }\n",
        "\n",
        "  for i in range(HPARAMS.num_neighbors):\n",
        "    nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
        "    nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)\n",
        "    feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
        "        [HPARAMS.max_seq_length],\n",
        "        tf.int64,\n",
        "        default_value=tf.constant(\n",
        "            0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
        "    \n",
        "    feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
        "        [1], tf.float32, default_value=tf.constant([0.0]))\n",
        "    \n",
        "  features = tf.io.parse_single_example(example_proto, feature_spec)\n",
        "  label = features.pop('label')\n",
        "  return features, label\n",
        "  \n",
        "    \n",
        "def make_dataset(file_path, training=False):\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset([file_path])\n",
        "  \n",
        "  if training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "  \n",
        "  dataset = dataset.map(parse_example)\n",
        "  dataset = dataset.batch(HPARAMS.batch_size)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "\n",
        "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
        "test_dataset = make_dataset(TEST_DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSW8TYzHdQVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "4a7c588c-7747-4a3d-9e7a-279d8adee380"
      },
      "source": [
        "for feature_batch, label_batch in train_dataset.take(1):\n",
        "  print('Lista cech:', list(feature_batch.keys()))\n",
        "  print('Wsad wejść:', feature_batch['words'])\n",
        "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
        "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
        "  print('Wsad sąsiednich wejść:', feature_batch[nbr_feature_key])\n",
        "  print('Wsad sąsiednich wag:', \n",
        "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
        "  print('Wsad etykiet:', label_batch)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lista cech: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
            "Wsad wejść: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Wsad sąsiednich wejść: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Wsad sąsiednich wag: tf.Tensor(\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
            "Wsad etykiet: tf.Tensor(\n",
            "[1 3 1 6 1 2 1 2 2 2 4 5 3 2 2 5 3 5 2 2 2 3 4 2 0 2 6 3 5 3 6 4 3 2 2 1 2\n",
            " 2 1 6 1 1 2 0 0 1 2 0 2 2 2 0 2 1 3 5 3 6 2 6 2 6 6 2 6 1 3 1 2 1 3 2 2 3\n",
            " 2 2 3 3 3 2 2 2 4 3 2 3 3 2 2 1 6 2 3 6 5 3 3 1 2 5 3 6 1 2 3 2 0 1 2 0 5\n",
            " 5 0 4 2 3 1 5 5 5 1 3 3 0 1 2 0 6], shape=(128,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEBX7jMbe0o6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "2909bc62-d7fb-4d9e-d806-816e964aa9d1"
      },
      "source": [
        "for feature_batch, label_batch in test_dataset.take(1):\n",
        "  print('Lista cech:', list(feature_batch.keys()))\n",
        "  print('Wsad wejść:', feature_batch['words'])\n",
        "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
        "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
        "  print('Wsad sąsiednich wejść:', feature_batch[nbr_feature_key])\n",
        "  print('Wsad sąsiednich wag:', \n",
        "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
        "  print('Wsad etykiet:', label_batch)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lista cech: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
            "Wsad wejść: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Wsad sąsiednich wejść: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Wsad sąsiednich wag: tf.Tensor(\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
            "Wsad etykiet: tf.Tensor(\n",
            "[5 2 2 2 1 2 6 3 2 3 6 1 3 6 4 4 2 3 3 0 2 0 5 2 1 0 6 3 6 4 2 2 3 0 4 2 2\n",
            " 2 2 3 2 2 2 0 2 2 2 2 4 2 3 4 0 2 6 2 1 4 2 0 0 1 4 2 6 0 5 2 2 3 2 5 2 5\n",
            " 2 3 2 2 2 2 2 6 6 3 2 4 2 6 3 2 2 6 2 4 2 2 1 3 4 6 0 0 2 4 2 1 3 6 6 2 6\n",
            " 6 6 1 4 6 4 3 6 6 0 0 2 6 2 4 0 0], shape=(128,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UjlqZfKfZsq",
        "colab_type": "text"
      },
      "source": [
        "## Budowa modelu\n",
        "### Model sekwencyjny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmzWb0o7gEPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_mlp_sequential_model(hparams):\n",
        "  '''Tworzy sekwencyjny perceptron wielowarstwowy.'''\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(\n",
        "      tf.keras.layers.InputLayer(\n",
        "          input_shape=(hparams.max_seq_length,), name='words'))\n",
        "  # Wejście jest już zakodowane w one-hot w formacie integer. \n",
        "  # Tutaj przerzucamy je do formatu zmiennoprzecinkowego.\n",
        "  model.add(\n",
        "      tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32)))\n",
        "  for num_units in hparams.num_fc_units:\n",
        "    model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(hparams.dropout_rate))\n",
        "  model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS5G2fECibe-",
        "colab_type": "text"
      },
      "source": [
        "### Model funkcjonalny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYJBKoMXid3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_mlp_functional_model(hparams):\n",
        "  '''Tworzy funkcjonalny bazowany na API perceptron wielowarstwowy.'''\n",
        "  inputs = tf.keras.Input(\n",
        "      shape=(hparams.max_seq_length,), dtype='int64', name='words')\n",
        "  \n",
        "  # Wejście jest już zakodowane w one-hot w formacie integer. \n",
        "  # Tutaj przerzucamy je do formatu zmiennoprzecinkowego.\n",
        "  cur_layer = tf.keras.layers.Lambda(\n",
        "      lambda x: tf.keras.backend.cast(x, tf.float32))(inputs)\n",
        "\n",
        "  for num_units in hparams.num_fc_units:\n",
        "    cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
        "    cur_layer = tf.keras.layers.Dropout(hparams.dropout_rate)(cur_layer)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(\n",
        "      hparams.num_classes, activation='softmax')(cur_layer)\n",
        "\n",
        "  model = tf.keras.Model(inputs, outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwyY5zY5lIHn",
        "colab_type": "text"
      },
      "source": [
        "## Tworzenie modelu bazowego"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utzh68sklVUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "5881a01c-f42f-439c-fcc5-83b7a5e166fe"
      },
      "source": [
        "# Tworzy model bazowy MLP z użyciem funkcjonalnego API.\n",
        "# Możemy również stworzyć model sekwencyjny używając\n",
        "# funkcji make_mlp_sequential_model() zdefiniowanej powyżej.\n",
        "base_model_tag, base_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)\n",
        "base_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "words (InputLayer)           [(None, 1433)]            0         \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 1433)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                71700     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 74,760\n",
            "Trainable params: 74,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCG6kpnenAQ2",
        "colab_type": "text"
      },
      "source": [
        "## Trenowanie modelu MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQCL3Urkm7dj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77ab413e-56fb-42d7-d57b-79dd1f8e00d7"
      },
      "source": [
        "# Kompilacja i trening\n",
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 2s 121ms/step - loss: 2.2394 - accuracy: 0.1893\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2.0852 - accuracy: 0.2872\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.9035 - accuracy: 0.3341\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.7467 - accuracy: 0.3708\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.5925 - accuracy: 0.4329\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.4380 - accuracy: 0.5077\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.2648 - accuracy: 0.5731\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.1451 - accuracy: 0.6093\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1.0304 - accuracy: 0.6585\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.9264 - accuracy: 0.6993\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.8463 - accuracy: 0.7239\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.7628 - accuracy: 0.7522\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.7097 - accuracy: 0.7870\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.6448 - accuracy: 0.7972\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5990 - accuracy: 0.8130\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5441 - accuracy: 0.8381\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.8469\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4638 - accuracy: 0.8571\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4582 - accuracy: 0.8659\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4228 - accuracy: 0.8673\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.3861 - accuracy: 0.8919\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3556 - accuracy: 0.8937\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.3399 - accuracy: 0.8988\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.3451 - accuracy: 0.9021\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.2892 - accuracy: 0.9123\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.2881 - accuracy: 0.9104\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.2704 - accuracy: 0.9225\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.2457 - accuracy: 0.9327\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.2460 - accuracy: 0.9285\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.2479 - accuracy: 0.9225\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.2202 - accuracy: 0.9420\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.2147 - accuracy: 0.9378\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2105 - accuracy: 0.9369\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9439\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1749 - accuracy: 0.9508\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9476\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.9578\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1569 - accuracy: 0.9601\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1621 - accuracy: 0.9541\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1539 - accuracy: 0.9559\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1584 - accuracy: 0.9531\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1500 - accuracy: 0.9647\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1398 - accuracy: 0.9601\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1394 - accuracy: 0.9643\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1394 - accuracy: 0.9619\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.9606\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1250 - accuracy: 0.9638\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1200 - accuracy: 0.9675\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1129 - accuracy: 0.9698\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 0.9633\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1082 - accuracy: 0.9717\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1114 - accuracy: 0.9689\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9805\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.9680\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0949 - accuracy: 0.9694\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1040 - accuracy: 0.9698\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0973 - accuracy: 0.9777\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0989 - accuracy: 0.9712\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0947 - accuracy: 0.9763\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9722\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0928 - accuracy: 0.9745\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0889 - accuracy: 0.9791\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 0.9787\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9726\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0783 - accuracy: 0.9800\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0726 - accuracy: 0.9810\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0766 - accuracy: 0.9800\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0789 - accuracy: 0.9800\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9833\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0701 - accuracy: 0.9833\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9856\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0698 - accuracy: 0.9814\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.9787\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0664 - accuracy: 0.9810\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0681 - accuracy: 0.9791\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9800\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9796\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.9842\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9865\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.9838\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0591 - accuracy: 0.9833\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0595 - accuracy: 0.9847\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0532 - accuracy: 0.9861\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9819\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 0.9847\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9810\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9875\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9861\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 0.9810\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9903\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.9875\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0566 - accuracy: 0.9861\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9856\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0511 - accuracy: 0.9842\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9865\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.9819\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0503 - accuracy: 0.9889\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0460 - accuracy: 0.9865\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0522 - accuracy: 0.9852\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0006ff3588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogJ13jhnnz29",
        "colab_type": "text"
      },
      "source": [
        "## Ocena modelu MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAxeO8X5n195",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funkcja pomocnicza do wyświetlenia oceny metryki.\n",
        "def print_metrics(model_desc, eval_metrics):\n",
        "\n",
        "  print('\\n')\n",
        "  print('Ocena dokładności dla ', model_desc, ': ', eval_metrics['accuracy'])\n",
        "  print('Ocena straty dla ', model_desc, ': ', eval_metrics['loss'])\n",
        "  if 'graph_loss' in eval_metrics:\n",
        "    print('Ocena straty grafu dla: ', model_desc, ': ', eval_metrics['graph_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUKXQ99yo_a5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3dd46f78-0713-4b50-aae6-882f84c7aca6"
      },
      "source": [
        "eval_results = dict(\n",
        "    zip(base_model.metrics_names,\n",
        "        base_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
        "print_metrics('Model bazowy MLP', eval_results)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2421 - accuracy: 0.7884\n",
            "\n",
            "\n",
            "Ocena dokładności dla  Model bazowy MLP :  0.78842676\n",
            "Ocena straty dla  Model bazowy MLP :  1.242060649394989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD5cp04wpxEZ",
        "colab_type": "text"
      },
      "source": [
        "## Trenowanie modelu MLP z regularyzacją grafu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5WchDHDp1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Budowa nowego bazowego modelu MLP.\n",
        "base_reg_model_tag, base_reg_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR6FkvtpqPQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5facd330-0855-4703-cb1d-ca3fff2c83ea"
      },
      "source": [
        "graph_reg_config = nsl.configs.make_graph_reg_config(\n",
        "    max_neighbors = HPARAMS.num_neighbors,\n",
        "    multiplier = HPARAMS.graph_regularization_multiplier,\n",
        "    distance_type = HPARAMS.distance_type,\n",
        "    sum_over_axis = -1)\n",
        "graph_reg_model = nsl.keras.GraphRegularization(base_reg_model,\n",
        "                                                graph_reg_config)\n",
        "graph_reg_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "graph_reg_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 2s 103ms/step - loss: 2.2285 - accuracy: 0.1689 - graph_loss: 0.0062\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2.0685 - accuracy: 0.2724 - graph_loss: 0.0157\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1.9114 - accuracy: 0.3104 - graph_loss: 0.0378\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1.7506 - accuracy: 0.3610 - graph_loss: 0.0642\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1.6132 - accuracy: 0.4255 - graph_loss: 0.0863\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 1.4572 - accuracy: 0.4854 - graph_loss: 0.1143\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1.3511 - accuracy: 0.5258 - graph_loss: 0.1450\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1.2085 - accuracy: 0.5763 - graph_loss: 0.1823\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 1.1051 - accuracy: 0.6381 - graph_loss: 0.2104\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1.0048 - accuracy: 0.6654 - graph_loss: 0.2332\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.9073 - accuracy: 0.7188 - graph_loss: 0.2414\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.8238 - accuracy: 0.7378 - graph_loss: 0.2568\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.7572 - accuracy: 0.7633 - graph_loss: 0.2871\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.6999 - accuracy: 0.7819 - graph_loss: 0.2983\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.6758 - accuracy: 0.7921 - graph_loss: 0.3026\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.6020 - accuracy: 0.8200 - graph_loss: 0.3141\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.5672 - accuracy: 0.8302 - graph_loss: 0.3191\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.5211 - accuracy: 0.8501 - graph_loss: 0.3150\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.4859 - accuracy: 0.8580 - graph_loss: 0.3332\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.5003 - accuracy: 0.8599 - graph_loss: 0.3298\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4407 - accuracy: 0.8794 - graph_loss: 0.3272\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8905 - graph_loss: 0.3261\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.3970 - accuracy: 0.8891 - graph_loss: 0.3297\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8886 - graph_loss: 0.3313\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.3448 - accuracy: 0.9090 - graph_loss: 0.3291\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.3297 - accuracy: 0.9132 - graph_loss: 0.3354\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.3203 - accuracy: 0.9137 - graph_loss: 0.3304\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.3060 - accuracy: 0.9193 - graph_loss: 0.3392\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2876 - accuracy: 0.9253 - graph_loss: 0.3304\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.2804 - accuracy: 0.9332 - graph_loss: 0.3413\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2617 - accuracy: 0.9392 - graph_loss: 0.3264\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.2493 - accuracy: 0.9397 - graph_loss: 0.3453\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.2649 - accuracy: 0.9341 - graph_loss: 0.3582\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2452 - accuracy: 0.9420 - graph_loss: 0.3324\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.2272 - accuracy: 0.9466 - graph_loss: 0.3438\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.2150 - accuracy: 0.9490 - graph_loss: 0.3422\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1990 - accuracy: 0.9564 - graph_loss: 0.3402\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.2163 - accuracy: 0.9494 - graph_loss: 0.3529\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1865 - accuracy: 0.9531 - graph_loss: 0.3497\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1992 - accuracy: 0.9573 - graph_loss: 0.3395\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1902 - accuracy: 0.9582 - graph_loss: 0.3377\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9624 - graph_loss: 0.3362\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1771 - accuracy: 0.9606 - graph_loss: 0.3507\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9568 - graph_loss: 0.3506\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1579 - accuracy: 0.9680 - graph_loss: 0.3409\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1683 - accuracy: 0.9652 - graph_loss: 0.3342\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1556 - accuracy: 0.9698 - graph_loss: 0.3532\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1533 - accuracy: 0.9703 - graph_loss: 0.3304\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1569 - accuracy: 0.9675 - graph_loss: 0.3445\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1559 - accuracy: 0.9698 - graph_loss: 0.3450\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1512 - accuracy: 0.9643 - graph_loss: 0.3483\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1397 - accuracy: 0.9712 - graph_loss: 0.3460\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1401 - accuracy: 0.9689 - graph_loss: 0.3430\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1382 - accuracy: 0.9745 - graph_loss: 0.3457\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1327 - accuracy: 0.9777 - graph_loss: 0.3495\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1442 - accuracy: 0.9675 - graph_loss: 0.3416\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1333 - accuracy: 0.9763 - graph_loss: 0.3418\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.9675 - graph_loss: 0.3385\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1192 - accuracy: 0.9782 - graph_loss: 0.3463\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1342 - accuracy: 0.9759 - graph_loss: 0.3466\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1252 - accuracy: 0.9740 - graph_loss: 0.3471\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1329 - accuracy: 0.9749 - graph_loss: 0.3483\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1273 - accuracy: 0.9717 - graph_loss: 0.3458\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9782 - graph_loss: 0.3448\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1134 - accuracy: 0.9805 - graph_loss: 0.3519\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1150 - accuracy: 0.9763 - graph_loss: 0.3516\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1122 - accuracy: 0.9814 - graph_loss: 0.3288\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1114 - accuracy: 0.9819 - graph_loss: 0.3363\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1124 - accuracy: 0.9800 - graph_loss: 0.3430\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1103 - accuracy: 0.9800 - graph_loss: 0.3448\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1132 - accuracy: 0.9800 - graph_loss: 0.3450\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1063 - accuracy: 0.9819 - graph_loss: 0.3399\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1102 - accuracy: 0.9773 - graph_loss: 0.3446\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1150 - accuracy: 0.9810 - graph_loss: 0.3397\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9824 - graph_loss: 0.3436\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1055 - accuracy: 0.9800 - graph_loss: 0.3403\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0982 - accuracy: 0.9819 - graph_loss: 0.3340\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1078 - accuracy: 0.9782 - graph_loss: 0.3496\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0983 - accuracy: 0.9856 - graph_loss: 0.3360\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9819 - graph_loss: 0.3435\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0937 - accuracy: 0.9865 - graph_loss: 0.3421\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0957 - accuracy: 0.9842 - graph_loss: 0.3371\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0970 - accuracy: 0.9838 - graph_loss: 0.3290\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0947 - accuracy: 0.9842 - graph_loss: 0.3434\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0965 - accuracy: 0.9828 - graph_loss: 0.3441\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0928 - accuracy: 0.9824 - graph_loss: 0.3330\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0925 - accuracy: 0.9870 - graph_loss: 0.3337\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0954 - accuracy: 0.9828 - graph_loss: 0.3489\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0875 - accuracy: 0.9884 - graph_loss: 0.3325\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0993 - accuracy: 0.9805 - graph_loss: 0.3432\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0918 - accuracy: 0.9856 - graph_loss: 0.3325\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.9847 - graph_loss: 0.3430\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0869 - accuracy: 0.9847 - graph_loss: 0.3369\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9842 - graph_loss: 0.3413\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0853 - accuracy: 0.9870 - graph_loss: 0.3431\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0800 - accuracy: 0.9889 - graph_loss: 0.3350\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0809 - accuracy: 0.9856 - graph_loss: 0.3469\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0936 - accuracy: 0.9819 - graph_loss: 0.3396\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0896 - accuracy: 0.9856 - graph_loss: 0.3396\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0777 - accuracy: 0.9916 - graph_loss: 0.3377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00069f45c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSL9RSADutv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "84eaca2d-9ef9-43d6-86e6-2fb794992cdd"
      },
      "source": [
        "eval_results = dict(\n",
        "    zip(graph_reg_model.metrics_names,\n",
        "        graph_reg_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
        "print_metrics('MLP + regularyzacja grafu', eval_results)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 95ms/step - loss: 1.1085 - accuracy: 0.8119 - graph_loss: 0.0000e+00\n",
            "\n",
            "\n",
            "Ocena dokładności dla  MLP + regularyzacja grafu :  0.8119349\n",
            "Ocena straty dla  MLP + regularyzacja grafu :  1.1085497200489045\n",
            "Ocena straty grafu dla:  MLP + regularyzacja grafu :  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
