{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stargan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRv9RU/sG0db0n1U8doerl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PsorTheDoctor/Sekcja-SI/blob/master/neural_networks/GAN/stargan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp3oT-_0XHTK",
        "colab_type": "text"
      },
      "source": [
        "# StarGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_bsXpbL4aMK",
        "colab_type": "text"
      },
      "source": [
        "## Import bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ElOTCaqQzjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7bvqMqRtkBA",
        "colab_type": "text"
      },
      "source": [
        "## Hiperparametry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0iZXNUntgu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('images', exist_ok=True)\n",
        "os.makedirs('saved_models', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tCbVnvquDXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 0                          # epoka, od której zaczyna się trening\n",
        "n_epochs = 200                     # ilość epok \n",
        "dataset_name = 'img_align_celeba_4000'  # nazwa zbioru danych \n",
        "batch_size = 16                    # rozmiar wsadów\n",
        "lr = 0.0002                        # współczynnik uczenia\n",
        "b1 = 0.5                           # momentum pierwszego rzędu gradientu\n",
        "b2 = 0.999                         # momentum pierwszego rzędu gradientu\n",
        "decay_epoch = 100                  # epoka, od której zaczyna się spadek współczynnika uczenia\n",
        "n_cpu = 8                          # ilość wątków cpu użytych podczas generacji wsadu\n",
        "img_height = 128                   # wysokość obrazu\n",
        "img_width = 128                    # szerokość obrazu\n",
        "channels = 3                       # ilość kanałów\n",
        "sample_interval = 400              # przerwa między zapisem próbek generatora\n",
        "checkpoint_interval = -1           # przerwa między punktami kontrolnymi modelu\n",
        "residual_blocks = 6                # ilość bloków w generatorze\n",
        "\n",
        "# wybrane atrybuty do zbioru danych CelebA\n",
        "selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
        "\n",
        "n_critic = 5                       # ilość iteracji trenowania dyskryminatora WGAN\n",
        "\n",
        "c_dim = len(selected_attrs)\n",
        "img_shape = (channels, img_height, img_width)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElnBrvqUvaG5",
        "colab_type": "code",
        "outputId": "8526578b-c1ce-4c49-f4e0-ed04636bb31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRElhjxevnH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funkcje straty\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "\n",
        "def criterion_cls(logit, target):\n",
        "  return F.binary_cross_entropy_with_logits(logit, target, size_average=False) / logit.size(0)\n",
        "\n",
        "# Wagi straty\n",
        "lambda_cls = 1\n",
        "lambda_rec = 10\n",
        "lambda_gp = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XqK7lq3kjtx",
        "colab_type": "text"
      },
      "source": [
        "## Funkcje\n",
        "### Załadowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8z4QLMDkt8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_of_files = 2000\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, root, transforms_=None, mode='train', attributes=None):\n",
        "    self.transform = transforms.Compose(transforms_)\n",
        "\n",
        "    self.selected_attrs = attributes \n",
        "    self.files = sorted(glob.glob('%s/*.jpg' % root))\n",
        "    self.files = self.files[:-2000] if mode == 'train' else self.files[-2000:]\n",
        "    self.label_path = glob.glob('%s/*.txt' % root)[0]\n",
        "    self.annotations = self.get_annotations()\n",
        "\n",
        "  def get_annotations(self):\n",
        "    \"\"\"Wyodrębnia adnotacje dla CelebA\"\"\"\n",
        "    annotations = {}\n",
        "    lines = [line.rstrip() for line in open(self.label_path, 'r')]\n",
        "    self.label_names = lines[1].split()\n",
        "    for _, line in enumerate(lines[2:]):\n",
        "      filename, *values = line.split()\n",
        "      labels = []\n",
        "      for attr in self.selected_attrs:\n",
        "        idx = self.label_names.index(attr)\n",
        "        labels.append(1 * (values[idx] == '1'))\n",
        "      annotations[filename] = labels\n",
        "    return annotations\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    filepath = self.files[index % len(self.files)]\n",
        "    filename = filepath.split('/')[-1]\n",
        "    img = self.transform(Image.open(filepath))\n",
        "    label = self.annotations[filename]\n",
        "    label = torch.FloatTensor(np.array(label))\n",
        "\n",
        "    return img, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvL-L06sgMOQ",
        "colab_type": "text"
      },
      "source": [
        "### Budowa modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkmWVFOhXb0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init_normal(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    torch.nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeST-FDdX3Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    conv_block = [\n",
        "      nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n",
        "      nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n",
        "      nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n",
        "    ]\n",
        "\n",
        "    self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.conv_block(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbqBvs7xgQHo",
        "colab_type": "text"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yuU8ionaDSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorResNet(nn.Module):\n",
        "  def __init__(self, img_shape=(3, 128, 128), res_blocks=9, c_dim=5):\n",
        "    super(GeneratorResNet, self).__init__()\n",
        "    channels, img_size, _ = img_shape\n",
        "\n",
        "    # Wstępny blok konwolucyjny\n",
        "    model = [\n",
        "      nn.Conv2d(channels + c_dim, 64, 7, stride=1, padding=3, bias=False),\n",
        "      nn.InstanceNorm2d(64, affine=True, track_running_stats=True),\n",
        "      nn.ReLU(inplace=True)\n",
        "    ]\n",
        "\n",
        "    # Próbkowanie w dół\n",
        "    curr_dim = 64\n",
        "    for _ in range(2):\n",
        "      model += [\n",
        "        nn.Conv2d(curr_dim, curr_dim * 2, 4, stride=2, padding=1, bias=False),\n",
        "        nn.InstanceNorm2d(curr_dim* 2, affine=True, track_running_stats=True),\n",
        "        nn.ReLU(inplace=True),\n",
        "      ]\n",
        "      curr_dim *= 2\n",
        "\n",
        "    # Pozostałe bloki\n",
        "    for _ in range(res_blocks):\n",
        "      model += [ResidualBlock(curr_dim)]\n",
        "\n",
        "    # Próbkowanie w górę\n",
        "    for _ in range(2):\n",
        "      model += [\n",
        "        nn.ConvTranspose2d(curr_dim, curr_dim // 2, 4, stride=2, padding=1, bias=False),\n",
        "        nn.InstanceNorm2d(curr_dim // 2, affine=True, track_running_stats=True),\n",
        "        nn.ReLU(inplace=True),\n",
        "      ]\n",
        "      curr_dim = curr_dim // 2\n",
        "    \n",
        "    # Warstwa wyjściowa\n",
        "    model += [nn.Conv2d(curr_dim, channels, 7, stride=1, padding=3), nn.Tanh()]\n",
        "\n",
        "    self.model = nn.Sequential(*model)\n",
        "\n",
        "  def forward(self, x, c):\n",
        "    c = c.view(c.size(0), c.size(1), 1, 1)\n",
        "    c = c.repeat(1, 1, x.size(2), x.size(3))\n",
        "    x = torch.cat((x, c), 1)\n",
        "    return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l85unG2GgWiZ",
        "colab_type": "text"
      },
      "source": [
        "#### Dyskryminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW6lGJAaf920",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_shape=(3, 128, 128), c_dim=5, n_strided=6):\n",
        "    super(Discriminator, self).__init__()\n",
        "    channels, img_size, _ = img_shape\n",
        "\n",
        "    def discriminator_block(in_filters, out_filters):\n",
        "      \"\"\"Zwraca próbkowane w dół warstwy każdego bloku dyskryminatora\"\"\"\n",
        "      layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1), nn.LeakyReLU(0.01)]\n",
        "      return layers\n",
        "\n",
        "    layers = discriminator_block(channels, 64)\n",
        "    curr_dim = 64\n",
        "    for _ in range(n_strided - 1):\n",
        "      layers.extend(discriminator_block(curr_dim, curr_dim * 2))\n",
        "      curr_dim *= 2\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "    # Wyjście 1: PatchGAN\n",
        "    self.out1 = nn.Conv2d(curr_dim, 1, 3, padding=1, bias=False)\n",
        "    # Wyjście 2: Predykcja klasy\n",
        "    kernel_size = img_size // 2 ** n_strided\n",
        "    self.out2 = nn.Conv2d(curr_dim, c_dim, kernel_size, bias=False)\n",
        "\n",
        "  def forward(self, img):\n",
        "    feature_repr = self.model(img)\n",
        "    out_adv = self.out1(feature_repr)\n",
        "    out_cls = self.out2(feature_repr)\n",
        "    return out_adv, out_cls.view(out_cls.size(0), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPtk8ZPNxkqV",
        "colab_type": "text"
      },
      "source": [
        "## Inicjalizacja modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z7wgsFlxanw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inicjalizacja generatora i dyskryminatora\n",
        "generator = GeneratorResNet(img_shape=img_shape, res_blocks=residual_blocks, c_dim=c_dim)\n",
        "discriminator = Discriminator(img_shape=img_shape, c_dim=c_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh9I9t5mzgxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if cuda:\n",
        "  generator = generator.cuda()\n",
        "  discriminator = discriminator.cuda()\n",
        "  criterion_cycle.cuda()\n",
        "\n",
        "if epoch != 0:\n",
        "  # Załadowanie przetrenowanych modeli\n",
        "  generator.load_state_dict(torch.load('saved_models/generator_%d.pth' % epoch))\n",
        "  discriminator.load_state_dict(torch.load('saved_models/discriminator_%d.pth' % epoch))\n",
        "else:\n",
        "  generator.apply(weights_init_normal)\n",
        "  discriminator.apply(weights_init_normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VA9gWz54zNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optymalizatory\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwxJ8MCA5Nf4",
        "colab_type": "text"
      },
      "source": [
        "## Załadowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW58Sh717pEC",
        "colab_type": "code",
        "outputId": "68ab3281-4ad8-4698-a55a-577f0991d6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I0ptP2MYVuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile('/content/drive/My Drive/img_align_celeba_4000.zip', 'r')\n",
        "# zip_ref.extractall('/content/drive/My Drive')\n",
        "# zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWU_5Qt1uJ4u",
        "colab_type": "text"
      },
      "source": [
        "### Zbiór treningowy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkurGPVD48PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Konfiguracja ładowania danych\n",
        "train_transforms = [\n",
        "  transforms.Resize(int(1.12 * img_height), Image.BICUBIC),\n",
        "  transforms.RandomCrop(img_height),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihK1UgpO6F8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = DataLoader(\n",
        "    CelebADataset(\n",
        "        '/content/drive/My Drive/%s' % dataset_name, transforms_=train_transforms, mode='train', attributes=selected_attrs\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrfOtLlOuSe3",
        "colab_type": "text"
      },
      "source": [
        "### Zbiór walidacyjny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MvSKoF8uUyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_transforms = [\n",
        "  transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92_lZlT3uzx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataloader = DataLoader(\n",
        "    CelebADataset(\n",
        "        '/content/drive/My Drive/%s' % dataset_name, transforms_=val_transforms, mode='val', attributes=selected_attrs\n",
        "    ),\n",
        "    batch_size=10,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hPEXyijIF6s",
        "colab_type": "text"
      },
      "source": [
        "## Funkcje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0NPRCoF_uJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Typ tensora\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCGoFHf-_8VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "  # Losowa waga do interpolacji między prawdziwymi i fałszywymi próbkami\n",
        "  alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
        "  # Wzięcie losowej interpolacji między prawdziwymi i fałszywymi próbkami\n",
        "  interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "  d_interpolates, _ = D(interpolates)\n",
        "  fake = Variable(Tensor(np.ones(d_interpolates.shape)), requires_grad=False)\n",
        "  \n",
        "  gradients = autograd.grad(\n",
        "      outputs=d_interpolates,\n",
        "      inputs=interpolates,\n",
        "      grad_outputs=fake,\n",
        "      create_graph=True,\n",
        "      retain_graph=True,\n",
        "      only_inputs=True,\n",
        "  )[0]\n",
        "  gradients = gradients.view(gradients.size(0), -1)\n",
        "  gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "  return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsO6RH8NEifq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Działa tylko dla selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']!\n",
        "\n",
        "# (a, b)\n",
        "# a      - indeks cechy w selected_attrs, do której się odwołujemy\n",
        "# b = -1 - negacja \n",
        "# b = 0  - obojętność\n",
        "# b = 1  - wystąpienie\n",
        "\n",
        "label_changes = [\n",
        "  ((0, 1), (1, 0), (2, 0)),  # Ustawienie czarnych włosów\n",
        "  ((0, 0), (1, 1), (2, 0)),  # Ustawienie blond włosów\n",
        "  ((0, 0), (1, 0), (2, 1)),  # Ustawienie brązowych włosów\n",
        "  ((3, -1),),  # Zmiana płci\n",
        "  ((4, -1),),  # Zmiana wieku\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr08onErFd4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images(batches_done):\n",
        "  \"\"\"Zapis wygenerowanej próbki\"\"\"\n",
        "  val_imgs, val_labels = next(iter(val_dataloader))\n",
        "  val_imgs = Variable(val_imgs.type(Tensor))\n",
        "  val_labels = Variable(val_labels.type(Tensor))\n",
        "  img_samples = None\n",
        "  for i in range(10):\n",
        "    img, label = val_imgs[i], val_labels[i]\n",
        "    \n",
        "    imgs = img.repeat(c_dim, 1, 1, 1)\n",
        "    labels = label.repeat(c_dim, 1)\n",
        "\n",
        "    for sample_i, changes in enumerate(label_changes):\n",
        "      for col, val in changes:\n",
        "        labels[sample_i, col] = 1 - labels[sample_i, col] if val == -1 else val\n",
        "    \n",
        "    gen_imgs = generator(imgs, labels)\n",
        "    gen_imgs = torch.cat([x for x in gen_imgs.data], -1)\n",
        "    img_sample = torch.cat((img.data, gen_imgs), -1)\n",
        "\n",
        "    img_samples = img_sample if img_samples is None else torch.cat((img_samples, img_sample), -2)\n",
        "\n",
        "  save_image(img_samples.view(1, *img_samples.shape), 'images/%s.png' % batches_done, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3kAt8FIIXfY",
        "colab_type": "text"
      },
      "source": [
        "## Trening modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCKpHEEuIWe3",
        "colab_type": "code",
        "outputId": "f998ef0b-6835-4545-afa4-7dddb7c6dc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "saved_samples = []\n",
        "start_time = time.time()\n",
        "for epoch in range(epoch, n_epochs):\n",
        "  for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "    # Wejścia modelu\n",
        "    imgs = Variable(imgs.type(Tensor))\n",
        "    labels = Variable(labels.type(Tensor))\n",
        "\n",
        "    # Przykładowe etykiety wejść generatora\n",
        "    sampled_c = Variable(Tensor(np.random.randint(0, 2, (imgs.size(0), c_dim))))\n",
        "    # Generacja fałszywego wsadu obrazów\n",
        "    fake_imgs = generator(imgs, sampled_c)\n",
        "\n",
        "    # Trening dyskryminatora\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    # Prawdziwe obrazy\n",
        "    real_validity, pred_cls = discriminator(imgs)\n",
        "    # Fałszywe obrazy\n",
        "    fake_validity, _ = discriminator(fake_imgs.detach())\n",
        "\n",
        "    gradient_penalty = compute_gradient_penalty(discriminator, imgs.data, fake_imgs.data)\n",
        "    # Strata antagonistyczna\n",
        "    loss_D_adv = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
        "    # Strata klasyfikacji\n",
        "    loss_D_cls = criterion_cls(pred_cls, labels)\n",
        "    # Strata całkowita\n",
        "    loss_D = loss_D_adv + lambda_cls * loss_D_cls\n",
        "\n",
        "    loss_D.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    if i % n_critic == 0:\n",
        "\n",
        "      # Trening generatora\n",
        "\n",
        "      # Tłumaczenie i rekonstrukcja obrazu\n",
        "      gen_imgs = generator(imgs, sampled_c)\n",
        "      recov_imgs = generator(gen_imgs, labels)\n",
        "      # Dyskryminator rozważa przetłumaczony obraz\n",
        "      fake_validity, pred_cls = discriminator(gen_imgs)\n",
        "      # Strata antagonistyczna\n",
        "      loss_G_adv = -torch.mean(fake_validity)\n",
        "      # Strata klasyfikacji\n",
        "      loss_G_cls = criterion_cls(pred_cls, sampled_c)\n",
        "      # Strata rekonstrukcji\n",
        "      loss_G_rec = criterion_cycle(recov_imgs, imgs)\n",
        "      # Strata całkowita\n",
        "      loss_G = loss_G_adv + lambda_cls * loss_G_cls + lambda_rec * loss_G_rec\n",
        "      \n",
        "      loss_G.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "      # Logi postępu\n",
        "\n",
        "      batches_done = epoch * len(dataloader) + i\n",
        "      batches_left = n_epochs * len(dataloader) - batches_done\n",
        "      time_left = datetime.timedelta(seconds=batches_left * (time.time() - start_time) / (batches_done + 1))\n",
        "\n",
        "      # Wypisz log\n",
        "      sys.stdout.write(\n",
        "          '\\r[Epoch %d/%d] [Batch %d/%d] [D adv: %f, aux: %f] [G loss: %f, adv: %f, aux: %f, cycle: %f] ETA: %s'\n",
        "          % (\n",
        "             epoch,\n",
        "             n_epochs,\n",
        "             i,\n",
        "             len(dataloader),\n",
        "             loss_D_adv.item(),\n",
        "             loss_D_cls.item(),\n",
        "             loss_G.item(),\n",
        "             loss_G_adv.item(),\n",
        "             loss_G_cls.item(),\n",
        "             loss_G_rec.item(),\n",
        "             time_left,\n",
        "          )\n",
        "      )\n",
        "\n",
        "      if batches_done % sample_interval == 0:\n",
        "        sample_images(batches_done)\n",
        "\n",
        "  if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
        "    # Zapis punktów kontrolnych modelu\n",
        "    torch.save(generator.state_dict(), '/content/saved_models/generator_%d.pth' % epoch)\n",
        "    torch.save(discriminator.state_dict(), '/content/saved_models/discriminator_%d.pth' % epoch)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 199/200] [Batch 125/126] [D adv: -3.337196, aux: 4.035940] [G loss: 9.611263, adv: -0.089546, aux: 8.015087, cycle: 0.168572] ETA: 0:00:00.533382"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwxPR_VavQ1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(generator.state_dict(), '/content/saved_models/generator_%d.pth' % epoch)\n",
        "# torch.save(discriminator.state_dict(), '/content/drive/My Drive/discriminator_%d.pth' % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFYLyPZB5qwS",
        "colab_type": "text"
      },
      "source": [
        "## Pobranie przetrenowanych modeli i obrazów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHL4vrrQ4xRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/saved_models/discriminator_199.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdKuCL3A0oBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/saved_models/generator_199.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt2Z96f45KEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "d3b293e3-1d3e-49c8-faa8-d891997cd5e9"
      },
      "source": [
        "!zip -r /content/images.zip /content/images/\n",
        "files.download('/content/images.zip')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/images/ (stored 0%)\n",
            "  adding: content/images/19600.png (deflated 0%)\n",
            "  adding: content/images/12000.png (deflated 0%)\n",
            "  adding: content/images/20800.png (deflated 0%)\n",
            "  adding: content/images/6400.png (deflated 0%)\n",
            "  adding: content/images/3200.png (deflated 0%)\n",
            "  adding: content/images/10800.png (deflated 0%)\n",
            "  adding: content/images/7600.png (deflated 0%)\n",
            "  adding: content/images/15200.png (deflated 0%)\n",
            "  adding: content/images/22800.png (deflated 0%)\n",
            "  adding: content/images/16400.png (deflated 0%)\n",
            "  adding: content/images/0.png (deflated 0%)\n",
            "  adding: content/images/24000.png (deflated 0%)\n",
            "  adding: content/images/2000.png (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
