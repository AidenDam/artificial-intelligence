{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGnxSridVLcFl/Z7lVc4J1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PsorTheDoctor/artificial-intelligence/blob/master/modern_approach/forward_forward/forward_forward_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forward-Forward propagation"
      ],
      "metadata": {
        "id": "ZAovmTs66ICD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gYFTLW4K5qay"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MNIST_loaders(train_batch_size=50000, test_batch_size=10000):\n",
        "  transform = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize((0.1307,), (0.3081,)),\n",
        "      Lambda(lambda x: torch.flatten(x))\n",
        "  ])\n",
        "  train_loader = DataLoader(\n",
        "      MNIST('./data/', train=True, download=True, transform=transform),\n",
        "      batch_size=train_batch_size, shuffle=True\n",
        "  )\n",
        "  test_loader = DataLoader(\n",
        "      MNIST('./data/', train=False, download=True, transform=transform),\n",
        "      batch_size=test_batch_size, shuffle=False\n",
        "  )\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def overlay_y_on_x(x, y):\n",
        "  x_ = x.clone()\n",
        "  x_[:, :10] *= 0.0\n",
        "  x_[range(x.shape[0]), y] = x.max()\n",
        "  return x_"
      ],
      "metadata": {
        "id": "BeQ6BjzS9JLZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, dims):\n",
        "    super().__init__()\n",
        "    self.layers = []\n",
        "    for d in range(len(dims) - 1):\n",
        "      self.layers += [Layer(dims[d], dims[d + 1]).cuda()]\n",
        "\n",
        "  def predict(self, x):\n",
        "    goodness_per_label = []\n",
        "    for label in range(10):\n",
        "      h = overlay_y_on_x(x, label)\n",
        "      goodness = []\n",
        "      for layer in self.layers:\n",
        "        h = layer(h)\n",
        "        goodness += [h.pow(2).mean(1)]\n",
        "      goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
        "    goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "    return goodness_per_label.argmax(1)\n",
        "\n",
        "  def train(self, x_pos, x_neg):\n",
        "    h_pos, h_neg = x_pos, x_neg\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      print('Training layer', i, '...')\n",
        "      h_pos, h_neg = layer.train(h_pos, h_neg)"
      ],
      "metadata": {
        "id": "qRvPhl89--ap"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(nn.Linear):\n",
        "  def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n",
        "    super().__init__(in_features, out_features, bias, device, dtype)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.opt = Adam(self.parameters(), lr=0.03)\n",
        "    self.threshold = 2.0\n",
        "    self.epochs = 1000\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
        "    return self.relu(\n",
        "        torch.mm(x_direction, self.weight.T) +\n",
        "        self.bias.unsqueeze(0)\n",
        "    )\n",
        "\n",
        "  def train(self, x_pos, x_neg):\n",
        "    for i in tqdm(range(self.epochs)):\n",
        "      g_pos = self.forward(x_pos).pow(2).mean(1)\n",
        "      g_neg = self.forward(x_neg).pow(2).mean(1)\n",
        "      loss = torch.log(1 + torch.exp(torch.cat([\n",
        "          -g_pos + self.threshold,\n",
        "          g_neg - self.threshold\n",
        "      ]))).mean()\n",
        "      self.opt.zero_grad()\n",
        "      loss.backward()\n",
        "      self.opt.step()\n",
        "    return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
      ],
      "metadata": {
        "id": "MC3qw48jCR4P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "train_loader, test_loader = MNIST_loaders()\n",
        "\n",
        "net = Net([784, 500, 500])\n",
        "x, y = next(iter(train_loader))\n",
        "x, y = x.cuda(), y.cuda()\n",
        "x_pos = overlay_y_on_x(x, y)\n",
        "rnd = torch.randperm(x.size(0))\n",
        "x_neg = overlay_y_on_x(x, y[rnd])\n",
        "net.train(x_pos, x_neg)\n",
        "\n",
        "print('Train error:', 1.0 - net.predict(x).eq(y).float().mean().item())\n",
        "\n",
        "x_test, y_test = next(iter(test_loader))\n",
        "x_test, y_test = x_test.cuda(), y_test.cuda()\n",
        "\n",
        "print('Test error:', 1.0 - net.predict(x_test).eq(y_test).float().mean().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPfnhB-CE1fR",
        "outputId": "4a97be71-9d65-43ac-b568-760ee6abe41f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training layer 0 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:59<00:00, 16.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training layer 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:39<00:00, 25.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train error: 0.07084000110626221\n",
            "Test error: 0.06929999589920044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credits: Mohammad Pezeshki (https://github.com/mohammadpz)"
      ],
      "metadata": {
        "id": "iR-dwsMj8zzC"
      }
    }
  ]
}